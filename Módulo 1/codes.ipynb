{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'spacy.lang.pt.Portuguese'>\n",
      "['tok2vec', 'morphologizer', 'parser', 'lemmatizer', 'attribute_ruler', 'ner']\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('pt_core_news_lg')\n",
    "print(type(nlp))\n",
    "print(nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375\n",
      "<class 'spacy.tokens.doc.Doc'>\n"
     ]
    }
   ],
   "source": [
    "documento = nlp(\"As ações do Magazine Luiza S.A., Franca, Brasil, acumularam baixa de 70% ao ano. Assim já devolveram todos os ganhos do período da pandemeia\")\n",
    "print(len(documento.vocab))\n",
    "print(type(documento))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[As, ações, do, Magazine, Luiza]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = [t for t in documento]\n",
    "tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens:  ['As', 'ações', 'do', 'Magazine', 'Luiza', 'S.A.', ',', 'Franca', ',', 'Brasil', ',', 'acumularam', 'baixa', 'de', '70', '%', 'ao', 'ano', '.', 'Assim', 'já', 'devolveram', 'todos', 'os', 'ganhos', 'do', 'período', 'da', 'pandemeia']\n",
      "Formato:  ['Xx', 'xxxx', 'xx', 'Xxxxx', 'Xxxxx', 'X.X.', ',', 'Xxxxx', ',', 'Xxxxx', ',', 'xxxx', 'xxxx', 'xx', 'dd', '%', 'xx', 'xxx', '.', 'Xxxxx', 'xx', 'xxxx', 'xxxx', 'xx', 'xxxx', 'xx', 'xxxx', 'xx', 'xxxx']\n"
     ]
    }
   ],
   "source": [
    "print(\"Tokens: \", [token.text for token in documento])\n",
    "print(\"Formato: \", [token.shape_ for token in documento])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pos-taggin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As  -  DET  -  det  -  o  -  Xx\n",
      "ações  -  NOUN  -  nsubj  -  ação  -  xxxx\n",
      "do  -  ADP  -  case  -  de o  -  xx\n",
      "Magazine  -  PROPN  -  nmod  -  Magazine  -  Xxxxx\n",
      "Luiza  -  PROPN  -  appos  -  Luiza  -  Xxxxx\n",
      "S.A.  -  PROPN  -  flat:name  -  S.A.  -  X.X.\n",
      ",  -  PUNCT  -  punct  -  ,  -  ,\n",
      "Franca  -  PROPN  -  conj  -  Franca  -  Xxxxx\n",
      ",  -  PUNCT  -  punct  -  ,  -  ,\n",
      "Brasil  -  PROPN  -  conj  -  Brasil  -  Xxxxx\n",
      ",  -  PUNCT  -  punct  -  ,  -  ,\n",
      "acumularam  -  VERB  -  ROOT  -  acumular  -  xxxx\n",
      "baixa  -  NOUN  -  obj  -  baixa  -  xxxx\n",
      "de  -  ADP  -  case  -  de  -  xx\n",
      "70  -  NUM  -  nummod  -  70  -  dd\n",
      "%  -  SYM  -  nmod  -  %  -  %\n",
      "ao  -  ADP  -  case  -  a o  -  xx\n",
      "ano  -  NOUN  -  nmod  -  ano  -  xxx\n",
      ".  -  PUNCT  -  punct  -  .  -  .\n",
      "Assim  -  ADV  -  advmod  -  assim  -  Xxxxx\n",
      "já  -  ADV  -  advmod  -  já  -  xx\n",
      "devolveram  -  VERB  -  ROOT  -  devolver  -  xxxx\n",
      "todos  -  DET  -  det  -  todo  -  xxxx\n",
      "os  -  DET  -  det  -  o  -  xx\n",
      "ganhos  -  NOUN  -  obj  -  ganho  -  xxxx\n",
      "do  -  ADP  -  case  -  de o  -  xx\n",
      "período  -  NOUN  -  nmod  -  período  -  xxxx\n",
      "da  -  ADP  -  case  -  de o  -  xx\n",
      "pandemeia  -  NOUN  -  nmod  -  pandemeia  -  xxxx\n"
     ]
    }
   ],
   "source": [
    "for token in documento:\n",
    "  print(token.text, \" - \", token.pos_ , \" - \", token.dep_ , \" - \", token.lemma_ , \" - \", token.shape_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Morfologia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As  -  Definite=Def|Gender=Fem|Number=Plur|PronType=Art\n",
      "ações  -  Gender=Fem|Number=Plur\n",
      "do  -  Definite=Def|Gender=Masc|Number=Sing|PronType=Art\n",
      "Magazine  -  Gender=Fem|Number=Sing\n",
      "Luiza  -  Gender=Fem|Number=Sing\n",
      "S.A.  -  Number=Sing\n",
      ",  -  \n",
      "Franca  -  Gender=Fem|Number=Sing\n",
      ",  -  \n",
      "Brasil  -  Gender=Masc|Number=Sing\n",
      ",  -  \n",
      "acumularam  -  Mood=Ind|Number=Plur|Person=3|Tense=Past|VerbForm=Fin\n",
      "baixa  -  Gender=Fem|Number=Sing\n",
      "de  -  \n",
      "70  -  NumType=Card\n",
      "%  -  \n",
      "ao  -  Definite=Def|Gender=Masc|Number=Sing|PronType=Art\n",
      "ano  -  Gender=Masc|Number=Sing\n",
      ".  -  \n",
      "Assim  -  \n",
      "já  -  \n",
      "devolveram  -  Mood=Ind|Number=Plur|Person=3|Tense=Past|VerbForm=Fin\n",
      "todos  -  Gender=Masc|Number=Plur|PronType=Tot\n",
      "os  -  Definite=Def|Gender=Masc|Number=Plur|PronType=Art\n",
      "ganhos  -  Gender=Masc|Number=Plur\n",
      "do  -  Definite=Def|Gender=Masc|Number=Sing|PronType=Art\n",
      "período  -  Gender=Masc|Number=Sing\n",
      "da  -  Definite=Def|Gender=Fem|Number=Sing|PronType=Art\n",
      "pandemeia  -  Gender=Fem|Number=Sing\n"
     ]
    }
   ],
   "source": [
    "for token in documento:\n",
    "  print(token.text, \" - \", token.morph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As  -  DET\n",
      "ações  -  NOUN\n",
      "do  -  ADP\n",
      "Magazine  -  PROPN\n",
      "Luiza  -  PROPN\n",
      "S.A.  -  PROPN\n",
      ",  -  PUNCT\n",
      "Franca  -  PROPN\n",
      ",  -  PUNCT\n",
      "Brasil  -  PROPN\n",
      ",  -  PUNCT\n",
      "acumularam  -  VERB\n",
      "baixa  -  NOUN\n",
      "de  -  ADP\n",
      "70  -  NUM\n",
      "%  -  SYM\n",
      "ao  -  ADP\n",
      "ano  -  NOUN\n",
      ".  -  PUNCT\n",
      "Assim  -  ADV\n",
      "já  -  ADV\n",
      "devolveram  -  VERB\n",
      "todos  -  DET\n",
      "os  -  DET\n",
      "ganhos  -  NOUN\n",
      "do  -  ADP\n",
      "período  -  NOUN\n",
      "da  -  ADP\n",
      "pandemeia  -  NOUN\n"
     ]
    }
   ],
   "source": [
    "for token in documento:\n",
    "  print(token.text, \" - \", token.tag_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magazine Luiza S.A.  -  ORG\n",
      "Franca  -  LOC\n",
      "Brasil  -  LOC\n",
      "pandemeia  -  ORG\n"
     ]
    }
   ],
   "source": [
    "for ent in documento.ents:\n",
    "  print(ent.text, \" - \", ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As ações do Magazine Luiza S.A., Franca, Brasil, acumularam baixa de 70% ao ano. Assim já devolveram todos os ganhos do período da pandemeia\n",
      "['As', 'ações', 'Magazine', 'Luiza', 'S.A.', ',', 'Franca', ',', 'Brasil', ',', 'acumularam', 'baixa', '70', '%', 'ano', '.', 'Assim', 'devolveram', 'ganhos', 'período', 'pandemeia']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "token_lista = []\n",
    "for token in documento:\n",
    "  token_lista.append(token.text)\n",
    "\n",
    "stop_lista = []\n",
    "for words in nlp.Defaults.stop_words:\n",
    "  stop_lista.append(words)\n",
    "\n",
    "semstop = [word for word in token_lista if not word in stop_lista]\n",
    "\n",
    "print(documento.text)\n",
    "print(semstop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hash:  6013848609874238634\n",
      "Hash:  6013848609874238634\n",
      "String:  dados\n"
     ]
    }
   ],
   "source": [
    "print(\"Hash: \", nlp.vocab.strings[\"dados\"])\n",
    "print(\"Hash: \", documento.vocab.strings[\"dados\"])\n",
    "print(\"String: \", nlp.vocab.strings[6013848609874238634])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dados  -  6013848609874238634  -  True  -  True\n"
     ]
    }
   ],
   "source": [
    "lex = nlp.vocab[\"dados\"]\n",
    "print(lex.text, \" - \", lex.orth, \" - \", lex.is_alpha, \" - \", lex.is_lower)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.5255733  -1.0520301  -1.0489888   0.22808893 -2.7599888   0.91837215\n",
      " -1.6993556  -0.44524103 -2.209261   -1.2901455   0.9939946  -1.3996754\n",
      "  0.7378708  -1.6957022  -1.382649   -1.1241877   2.503239    1.3766589\n",
      " -0.63682556  2.7080245  -0.6679023   0.7990059  -1.3761922   1.6491444\n",
      " -0.6950322   0.69378555 -0.19840002  1.6926199  -0.3071023   0.71506053\n",
      "  0.03211441  0.27212894 -1.9055911  -1.5586021  -0.9775556   0.7999823\n",
      " -0.9553054   0.5265729  -0.87427455 -1.2073755  -2.117481    1.2241988\n",
      "  1.5149522  -0.79308677 -1.1521667   0.13741441 -1.7882053   0.50415283\n",
      "  1.3089666   0.06542712 -0.6260744  -1.5624356  -0.707184   -1.2425367\n",
      " -0.04237115 -0.5879791   1.7004043  -0.24798778  0.11633212 -0.55506223\n",
      "  2.0148706   0.01965364  0.92778563  2.3571968  -0.49526003  1.0151839\n",
      "  0.57112557  1.3510779  -0.3038622  -0.24523441 -0.42284998 -0.69732666\n",
      "  0.71998227  0.2875956   0.10309222 -0.6866155   2.128672    0.9791889\n",
      " -1.4044011  -0.4600078   0.10599887  0.84635675  1.2420444   0.40497887\n",
      "  0.24567226 -2.4633954   0.30174115 -1.2952554   0.5795323  -1.899822\n",
      " -0.74619776  2.998889    2.0798278  -0.9101444   0.27261782  0.3154811\n",
      "  3.1923532   1.315211   -3.1751957   0.03176559  1.1431444   1.6177245\n",
      " -1.0905743   0.6142689   1.0441045  -1.0070856  -0.6415578  -0.75415665\n",
      "  0.04653723 -0.7180089  -0.09737895  0.02209669 -0.43218002 -0.37869656\n",
      " -1.4787056  -0.8019056   2.2888644  -0.58004665 -0.35054     0.8161524\n",
      "  0.56656885 -3.1986172  -0.13080996 -0.87027764  0.19671117 -0.18788989\n",
      "  2.1433      0.5740978   0.79283893  1.1020746   0.06806201  0.14578162\n",
      " -0.48713335 -0.9247377   0.84602445  1.326062   -0.13929449 -2.2536204\n",
      "  0.8378011   1.8202833  -2.1101756   0.01467665 -0.1241987  -0.28894553\n",
      " -2.689321    0.35465997  1.3067889   0.78942555 -3.1275606  -0.70258003\n",
      "  1.1796956  -0.09419552 -0.39751524 -2.17274     0.00593225  0.11152443\n",
      " -0.40126875 -0.7324776  -1.110687   -1.6154889   1.9177108   0.59479684\n",
      " -0.9205568   1.6399556   2.1313922   0.8705971  -0.4869177  -2.5268655\n",
      " -0.20582779 -1.351448    1.0684322   1.0798033   0.7770678  -0.88195336\n",
      " -0.94633335 -1.6027511   2.097808   -0.44511667 -1.657932    1.3012689\n",
      "  1.4642056   0.07117888 -0.45494658  1.4971966   1.3140267  -0.48212782\n",
      "  1.0694442  -2.269592    1.3391188   1.5931556  -1.7781789  -1.465089\n",
      "  0.23485115 -2.34892     0.940096    0.5333122  -0.74473196 -1.2676699\n",
      " -0.40783006 -0.7384778  -2.09579     2.0488043  -1.182571    0.37707764\n",
      "  1.1301712   0.28928337  1.3739567  -1.0200423   1.2103223   0.04722336\n",
      "  1.3624822  -1.2681168   1.4688356   0.8132446  -1.719049    1.8276443\n",
      "  1.0804734  -0.31434     0.88836336 -0.67704093 -1.0336466  -0.9087268\n",
      "  0.09643783 -2.5777566  -0.08628993 -0.8835056  -0.5007     -2.010551\n",
      "  0.9359345  -1.839522   -0.45124334 -1.67075     0.1972278  -0.69528896\n",
      " -0.8587457  -0.25463215  0.23403136 -1.7613523   0.39325333  2.0033166\n",
      "  0.16394782 -0.5912411   0.4513964   0.38095444  0.9961722  -0.5356072\n",
      " -0.24399893  1.2084801   1.047721   -0.3533555  -0.68883884 -0.05879111\n",
      " -1.0547067  -0.9298345   0.1543278   0.22240782 -0.8161553   2.490319\n",
      " -1.5402923   0.59167856 -1.8444476   0.68242     2.5562222   0.99307674\n",
      "  0.02924996 -0.70853776 -1.0495977   0.13625993  2.1210868   1.4868933\n",
      "  3.163472   -0.43712902 -0.514627    2.9385633  -2.2680051   0.10609888\n",
      "  2.2179537   0.63511777  0.40360793 -1.1280782  -1.7189742  -0.46922117\n",
      "  2.9208887  -0.7004363  -0.36562064  1.1512333  -1.4175044  -0.44106555\n",
      " -0.48883343 -0.5042111   0.28768444  3.4773679  -1.2891389  -0.65457785\n",
      "  0.3968733  -1.9304742   2.1593056  -0.50640225 -1.4050981   1.26994   ]\n"
     ]
    }
   ],
   "source": [
    "print(nlp(\"dados são uma nova forma de ver o mundo\").vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8941741168014388\n",
      "0.8941741168014388\n"
     ]
    }
   ],
   "source": [
    "documento1 = nlp(\"Ele viaja regularmente de carro\")\n",
    "documento2 = nlp(\"Ela regularmente de avião viaja\")\n",
    "print(documento1.similarity(documento2))\n",
    "print(documento2.similarity(documento1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comprimento\n",
      "cumprimento\n",
      "0.5804340243339539\n"
     ]
    }
   ],
   "source": [
    "documento3 = nlp(\"Devemos dizer comprimento ou cumprimento?\")\n",
    "tokenA = documento3[2]\n",
    "print(tokenA)\n",
    "tokenB = documento3[4]\n",
    "print(tokenB)\n",
    "print(tokenA.similarity(tokenB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ele pede descrição\n",
      "Ele pede discrição\n",
      "0.9630053639411926\n"
     ]
    }
   ],
   "source": [
    "documento4 = nlp(\"Ele pede descrição. Ele pede discrição\")\n",
    "partA = documento4[0:3]\n",
    "print(partA)\n",
    "partB = documento4[4:7]\n",
    "print(partB)\n",
    "print(partA.similarity(partB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(51) - 9964656570\n",
      "(11) 12344988\n"
     ]
    }
   ],
   "source": [
    "from typing import Match\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "documento5 = nlp(\"Você pode ligar para (51) - 9964656570 ou (11) 12344988 \")\n",
    "\n",
    "matcher = Matcher(nlp.vocab)\n",
    "padrao = [{\"ORTH\": \"(\"} ,{\"SHAPE\": \"dd\"},{\"ORTH\": \")\"}, {\"ORTH\": \"-\", \"OP\":\"?\"} , {\"IS_DIGIT\": True}]\n",
    "matcher.add(\"telefone\", [padrao])\n",
    "matches = matcher(documento5)\n",
    "for id, inicio, fim in matches:\n",
    "  print(documento5[inicio:fim])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "micro organismos\n",
      "MICROORGANISMOS\n",
      "micro-organismos\n"
     ]
    }
   ],
   "source": [
    "documento6 = nlp(\"Estamos infectados com micro organismos. MICROORGANISMOS são perigosos. Não enxergamos micro-organismos\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "padrao1 = [{\"LOWER\":\"micro-organismos\"}]\n",
    "padrao2 = [{\"LOWER\":\"microorganismos\"}]\n",
    "padrao3 = [{\"LOWER\":\"micro\"}, {\"LOWER\":\"organismos\"}]\n",
    "\n",
    "matcher.add(\"padrao\", [padrao1,padrao2,padrao3])\n",
    "\n",
    "matches = matcher(documento6)\n",
    "for id, inicio, fim in matches:\n",
    "  print(documento6[inicio:fim])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">As ações do \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Magazine Luiza S.A.\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Franca\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Brasil\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", acumularam baixa de 70% ao ano. Assim já devolveram todos os ganhos do período da \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    pandemeia\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(documento,style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"pt\" id=\"08fd25d3c3264b93aba3ee7cf68b8ca1-0\" class=\"displacy\" width=\"1970\" height=\"337.0\" direction=\"ltr\" style=\"max-width: none; height: 337.0px; color: #FFFFFF; background: #000000; font-family: Arial; direction: ltr\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">As</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"130\">ações</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"130\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"210\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"210\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"290\">Magazine</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"290\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"370\">Luiza</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"370\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"450\">S.A.,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"450\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"530\">Franca,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"530\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"610\">Brasil,</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"610\">PROPN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"690\">acumularam</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"690\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">baixa</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"850\">de</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"850\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"930\">70%</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"930\">SYM</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1010\">ao</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1010\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1090\">ano.</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1090\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1170\">Assim</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1170\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">já</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">ADV</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1330\">devolveram</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1330\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1410\">todos</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1410\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1490\">os</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1490\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1570\">ganhos</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1570\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1650\">do</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1650\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1730\">período</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1730\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1810\">da</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1810\">ADP</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"247.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1890\">pandemeia</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1890\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-0\" stroke-width=\"2px\" d=\"M62,202.0 62,188.66666666666666 118.0,188.66666666666666 118.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,204.0 L58,196.0 66,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-1\" stroke-width=\"2px\" d=\"M142,202.0 142,135.33333333333331 690.0,135.33333333333331 690.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M142,204.0 L138,196.0 146,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-2\" stroke-width=\"2px\" d=\"M222,202.0 222,188.66666666666666 278.0,188.66666666666666 278.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M222,204.0 L218,196.0 226,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-3\" stroke-width=\"2px\" d=\"M142,202.0 142,175.33333333333334 281.0,175.33333333333334 281.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M281.0,204.0 L285.0,196.0 277.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-4\" stroke-width=\"2px\" d=\"M302,202.0 302,188.66666666666666 358.0,188.66666666666666 358.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">appos</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M358.0,204.0 L362.0,196.0 354.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-5\" stroke-width=\"2px\" d=\"M302,202.0 302,175.33333333333334 441.0,175.33333333333334 441.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">flat:name</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M441.0,204.0 L445.0,196.0 437.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-6\" stroke-width=\"2px\" d=\"M302,202.0 302,162.0 524.0,162.0 524.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M524.0,204.0 L528.0,196.0 520.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-7\" stroke-width=\"2px\" d=\"M302,202.0 302,148.66666666666666 607.0,148.66666666666666 607.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M607.0,204.0 L611.0,196.0 603.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-8\" stroke-width=\"2px\" d=\"M702,202.0 702,188.66666666666666 758.0,188.66666666666666 758.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M758.0,204.0 L762.0,196.0 754.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-9\" stroke-width=\"2px\" d=\"M862,202.0 862,188.66666666666666 918.0,188.66666666666666 918.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M862,204.0 L858,196.0 866,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-10\" stroke-width=\"2px\" d=\"M782,202.0 782,175.33333333333334 921.0,175.33333333333334 921.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M921.0,204.0 L925.0,196.0 917.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-11\" stroke-width=\"2px\" d=\"M1022,202.0 1022,188.66666666666666 1078.0,188.66666666666666 1078.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1022,204.0 L1018,196.0 1026,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-12\" stroke-width=\"2px\" d=\"M782,202.0 782,162.0 1084.0,162.0 1084.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1084.0,204.0 L1088.0,196.0 1080.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-13\" stroke-width=\"2px\" d=\"M1182,202.0 1182,175.33333333333334 1321.0,175.33333333333334 1321.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1182,204.0 L1178,196.0 1186,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-14\" stroke-width=\"2px\" d=\"M1262,202.0 1262,188.66666666666666 1318.0,188.66666666666666 1318.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">advmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1262,204.0 L1258,196.0 1266,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-15\" stroke-width=\"2px\" d=\"M1422,202.0 1422,175.33333333333334 1561.0,175.33333333333334 1561.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1422,204.0 L1418,196.0 1426,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-16\" stroke-width=\"2px\" d=\"M1502,202.0 1502,188.66666666666666 1558.0,188.66666666666666 1558.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1502,204.0 L1498,196.0 1506,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-17\" stroke-width=\"2px\" d=\"M1342,202.0 1342,162.0 1564.0,162.0 1564.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">obj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1564.0,204.0 L1568.0,196.0 1560.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-18\" stroke-width=\"2px\" d=\"M1662,202.0 1662,188.66666666666666 1718.0,188.66666666666666 1718.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1662,204.0 L1658,196.0 1666,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-19\" stroke-width=\"2px\" d=\"M1582,202.0 1582,175.33333333333334 1721.0,175.33333333333334 1721.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1721.0,204.0 L1725.0,196.0 1717.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-20\" stroke-width=\"2px\" d=\"M1822,202.0 1822,188.66666666666666 1878.0,188.66666666666666 1878.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1822,204.0 L1818,196.0 1826,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-21\" stroke-width=\"2px\" d=\"M1742,202.0 1742,175.33333333333334 1881.0,175.33333333333334 1881.0,202.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-08fd25d3c3264b93aba3ee7cf68b8ca1-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nmod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M1881.0,204.0 L1885.0,196.0 1877.0,196.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "documento.user_data['title'] = \"Exemplo\"\n",
    "displacy.render(documento,style=\"dep\", jupyter=True,\n",
    "                options={'compact': True, 'distance' : 80, 'color': '#FFFFFF', 'bg': '#000000', 'font': 'Arial' })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Normal:  ['tok2vec', 'morphologizer', 'parser', 'lemmatizer', 'attribute_ruler', 'ner']\n"
     ]
    }
   ],
   "source": [
    "print(\"Pipeline Normal: \", nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline sem tok2vec:  ['morphologizer', 'parser', 'lemmatizer', 'attribute_ruler', 'ner']\n"
     ]
    }
   ],
   "source": [
    "nlp.remove_pipe('tok2vec')\n",
    "print(\"Pipeline sem tok2vec: \", nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline Normal:  ['morphologizer', 'tok2vec', 'parser', 'lemmatizer', 'attribute_ruler', 'ner']\n"
     ]
    }
   ],
   "source": [
    "nlp.add_pipe('tok2vec', after='morphologizer')\n",
    "print(\"Pipeline Normal: \", nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pras/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /home/pras/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package tagsets to /home/pras/nltk_data...\n",
      "[nltk_data]   Unzipping help/tagsets.zip.\n",
      "[nltk_data] Downloading package wordnet to /home/pras/nltk_data...\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/pras/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/pras/nltk_data...\n",
      "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
      "[nltk_data] Downloading package words to /home/pras/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, SnowballStemmer, LancasterStemmer\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.tag import pos_tag, pos_tag_sents\n",
    "import string\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"tagsets\")\n",
    "nltk.download(\"wordnet\")\n",
    "nltk.download(\"averaged_perceptron_tagger\")\n",
    "nltk.download(\"maxent_ne_chunker\")\n",
    "nltk.download(\"words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Texto = \"As ações do Magazine Luiza S.A., Franca, Brasil, acumularam baixa de 70% ao ano. Assim já devolveram todos os ganhos do período da pandemeia\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "['As ações do Magazine Luiza S.A., Franca, Brasil, acumularam baixa de 70% ao ano.', 'Assim já devolveram todos os ganhos do período da pandemeia']\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "sentencas = sent_tokenize(Texto, language=\"portuguese\")\n",
    "print(type(sentencas))\n",
    "print(sentencas)\n",
    "print(len(sentencas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'ações', 'do', 'Magazine', 'Luiza', 'S.A.', ',', 'Franca', ',', 'Brasil', ',', 'acumularam', 'baixa', 'de', '70', '%', 'ao', 'ano', '.', 'Assim', 'já', 'devolveram', 'todos', 'os', 'ganhos', 'do', 'período', 'da', 'pandemeia']\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "tokens = word_tokenize(Texto, language=\"portuguese\")\n",
    "print(tokens)\n",
    "print(len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "207\n",
      "['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as', 'às', 'até', 'com', 'como', 'da', 'das', 'de', 'dela', 'delas', 'dele', 'deles', 'depois', 'do', 'dos', 'e', 'é', 'ela', 'elas', 'ele', 'eles', 'em', 'entre', 'era', 'eram', 'éramos', 'essa', 'essas', 'esse', 'esses', 'esta', 'está', 'estamos', 'estão', 'estar', 'estas', 'estava', 'estavam', 'estávamos', 'este', 'esteja', 'estejam', 'estejamos', 'estes', 'esteve', 'estive', 'estivemos', 'estiver', 'estivera', 'estiveram', 'estivéramos', 'estiverem', 'estivermos', 'estivesse', 'estivessem', 'estivéssemos', 'estou', 'eu', 'foi', 'fomos', 'for', 'fora', 'foram', 'fôramos', 'forem', 'formos', 'fosse', 'fossem', 'fôssemos', 'fui', 'há', 'haja', 'hajam', 'hajamos', 'hão', 'havemos', 'haver', 'hei', 'houve', 'houvemos', 'houver', 'houvera', 'houverá', 'houveram', 'houvéramos', 'houverão', 'houverei', 'houverem', 'houveremos', 'houveria', 'houveriam', 'houveríamos', 'houvermos', 'houvesse', 'houvessem', 'houvéssemos', 'isso', 'isto', 'já', 'lhe', 'lhes', 'mais', 'mas', 'me', 'mesmo', 'meu', 'meus', 'minha', 'minhas', 'muito', 'na', 'não', 'nas', 'nem', 'no', 'nos', 'nós', 'nossa', 'nossas', 'nosso', 'nossos', 'num', 'numa', 'o', 'os', 'ou', 'para', 'pela', 'pelas', 'pelo', 'pelos', 'por', 'qual', 'quando', 'que', 'quem', 'são', 'se', 'seja', 'sejam', 'sejamos', 'sem', 'ser', 'será', 'serão', 'serei', 'seremos', 'seria', 'seriam', 'seríamos', 'seu', 'seus', 'só', 'somos', 'sou', 'sua', 'suas', 'também', 'te', 'tem', 'tém', 'temos', 'tenha', 'tenham', 'tenhamos', 'tenho', 'terá', 'terão', 'terei', 'teremos', 'teria', 'teriam', 'teríamos', 'teu', 'teus', 'teve', 'tinha', 'tinham', 'tínhamos', 'tive', 'tivemos', 'tiver', 'tivera', 'tiveram', 'tivéramos', 'tiverem', 'tivermos', 'tivesse', 'tivessem', 'tivéssemos', 'tu', 'tua', 'tuas', 'um', 'uma', 'você', 'vocês', 'vos']\n"
     ]
    }
   ],
   "source": [
    "stops = stopwords.words(\"portuguese\")\n",
    "print(len(stops))\n",
    "print(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "As ações do Magazine Luiza S.A., Franca, Brasil, acumularam baixa de 70% ao ano. Assim já devolveram todos os ganhos do período da pandemeia\n",
      "['As', 'ações', 'Magazine', 'Luiza', 'S.A.', ',', 'Franca', ',', 'Brasil', ',', 'acumularam', 'baixa', '70', '%', 'ano', '.', 'Assim', 'devolveram', 'todos', 'ganhos', 'período', 'pandemeia']\n"
     ]
    }
   ],
   "source": [
    "palavras_sem_stopwords = [p for p in tokens if p not in stops]\n",
    "print(len(palavras_sem_stopwords))\n",
    "print(Texto)\n",
    "print(palavras_sem_stopwords)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "print(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17\n",
      "As ações do Magazine Luiza S.A., Franca, Brasil, acumularam baixa de 70% ao ano. Assim já devolveram todos os ganhos do período da pandemeia\n",
      "['As', 'ações', 'Magazine', 'Luiza', 'S.A.', 'Franca', 'Brasil', 'acumularam', 'baixa', '70', 'ano', 'Assim', 'devolveram', 'todos', 'ganhos', 'período', 'pandemeia']\n"
     ]
    }
   ],
   "source": [
    "palavras_sem_pontuacao = [p for p in palavras_sem_stopwords if p not in string.punctuation]\n",
    "print(len(palavras_sem_pontuacao))\n",
    "print(Texto)\n",
    "print(palavras_sem_pontuacao)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'As': 1, 'ações': 1, 'Magazine': 1, 'Luiza': 1, 'S.A.': 1, 'Franca': 1, 'Brasil': 1, 'acumularam': 1, 'baixa': 1, '70': 1, ...})"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencia = nltk.FreqDist(palavras_sem_pontuacao)\n",
    "frequencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('As', 1), ('ações', 1), ('Magazine', 1), ('Luiza', 1), ('S.A.', 1)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mais_comuns = frequencia.most_common(5)\n",
    "mais_comuns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'ações', 'Magazine', 'Luiza', 'S.A.', 'Franca', 'Brasil', 'acumularam', 'baixa', '70', 'ano', 'Assim', 'devolveram', 'todos', 'ganhos', 'período', 'pandemeia']\n",
      "['as', 'açõ', 'magazin', 'luiza', 's.a.', ',', 'franca', ',', 'brasil', ',', 'acumularam', 'baixa', '70', '%', 'ano', '.', 'assim', 'devolveram', 'todo', 'ganho', 'período', 'pandemeia']\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "stem1  = [stemmer.stem(word) for word in palavras_sem_stopwords]\n",
    "print(palavras_sem_pontuacao)\n",
    "print(stem1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'ações', 'Magazine', 'Luiza', 'S.A.', 'Franca', 'Brasil', 'acumularam', 'baixa', '70', 'ano', 'Assim', 'devolveram', 'todos', 'ganhos', 'período', 'pandemeia']\n",
      "['as', 'açõ', 'magazin', 'luiz', 's.a.', 'franc', 'brasil', 'acumul', 'baix', '70', 'ano', 'assim', 'devolv', 'tod', 'ganh', 'períod', 'pandem']\n"
     ]
    }
   ],
   "source": [
    "stemmer2 = SnowballStemmer(\"portuguese\")\n",
    "stem2 = [stemmer2.stem(word) for word in palavras_sem_pontuacao]\n",
    "print(palavras_sem_pontuacao)\n",
    "print(stem2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'ações', 'Magazine', 'Luiza', 'S.A.', 'Franca', 'Brasil', 'acumularam', 'baixa', '70', 'ano', 'Assim', 'devolveram', 'todos', 'ganhos', 'período', 'pandemeia']\n",
      "['as', 'açõ', 'magazin', 'luiz', 's.a.', 'franc', 'brasil', 'acumularam', 'baix', '70', 'ano', 'assim', 'devolveram', 'todo', 'ganho', 'período', 'pandeme']\n"
     ]
    }
   ],
   "source": [
    "stemmer3 = LancasterStemmer()\n",
    "stem3 = [stemmer3.stem(word) for word in palavras_sem_pontuacao]\n",
    "print(palavras_sem_pontuacao)\n",
    "print(stem3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$: dollar\n",
      "    $ -$ --$ A$ C$ HK$ M$ NZ$ S$ U.S.$ US$\n",
      "'': closing quotation mark\n",
      "    ' ''\n",
      "(: opening parenthesis\n",
      "    ( [ {\n",
      "): closing parenthesis\n",
      "    ) ] }\n",
      ",: comma\n",
      "    ,\n",
      "--: dash\n",
      "    --\n",
      ".: sentence terminator\n",
      "    . ! ?\n",
      ":: colon or ellipsis\n",
      "    : ; ...\n",
      "CC: conjunction, coordinating\n",
      "    & 'n and both but either et for less minus neither nor or plus so\n",
      "    therefore times v. versus vs. whether yet\n",
      "CD: numeral, cardinal\n",
      "    mid-1890 nine-thirty forty-two one-tenth ten million 0.5 one forty-\n",
      "    seven 1987 twenty '79 zero two 78-degrees eighty-four IX '60s .025\n",
      "    fifteen 271,124 dozen quintillion DM2,000 ...\n",
      "DT: determiner\n",
      "    all an another any both del each either every half la many much nary\n",
      "    neither no some such that the them these this those\n",
      "EX: existential there\n",
      "    there\n",
      "FW: foreign word\n",
      "    gemeinschaft hund ich jeux habeas Haementeria Herr K'ang-si vous\n",
      "    lutihaw alai je jour objets salutaris fille quibusdam pas trop Monte\n",
      "    terram fiche oui corporis ...\n",
      "IN: preposition or conjunction, subordinating\n",
      "    astride among uppon whether out inside pro despite on by throughout\n",
      "    below within for towards near behind atop around if like until below\n",
      "    next into if beside ...\n",
      "JJ: adjective or numeral, ordinal\n",
      "    third ill-mannered pre-war regrettable oiled calamitous first separable\n",
      "    ectoplasmic battery-powered participatory fourth still-to-be-named\n",
      "    multilingual multi-disciplinary ...\n",
      "JJR: adjective, comparative\n",
      "    bleaker braver breezier briefer brighter brisker broader bumper busier\n",
      "    calmer cheaper choosier cleaner clearer closer colder commoner costlier\n",
      "    cozier creamier crunchier cuter ...\n",
      "JJS: adjective, superlative\n",
      "    calmest cheapest choicest classiest cleanest clearest closest commonest\n",
      "    corniest costliest crassest creepiest crudest cutest darkest deadliest\n",
      "    dearest deepest densest dinkiest ...\n",
      "LS: list item marker\n",
      "    A A. B B. C C. D E F First G H I J K One SP-44001 SP-44002 SP-44005\n",
      "    SP-44007 Second Third Three Two * a b c d first five four one six three\n",
      "    two\n",
      "MD: modal auxiliary\n",
      "    can cannot could couldn't dare may might must need ought shall should\n",
      "    shouldn't will would\n",
      "NN: noun, common, singular or mass\n",
      "    common-carrier cabbage knuckle-duster Casino afghan shed thermostat\n",
      "    investment slide humour falloff slick wind hyena override subhumanity\n",
      "    machinist ...\n",
      "NNP: noun, proper, singular\n",
      "    Motown Venneboerger Czestochwa Ranzer Conchita Trumplane Christos\n",
      "    Oceanside Escobar Kreisler Sawyer Cougar Yvette Ervin ODI Darryl CTCA\n",
      "    Shannon A.K.C. Meltex Liverpool ...\n",
      "NNPS: noun, proper, plural\n",
      "    Americans Americas Amharas Amityvilles Amusements Anarcho-Syndicalists\n",
      "    Andalusians Andes Andruses Angels Animals Anthony Antilles Antiques\n",
      "    Apache Apaches Apocrypha ...\n",
      "NNS: noun, common, plural\n",
      "    undergraduates scotches bric-a-brac products bodyguards facets coasts\n",
      "    divestitures storehouses designs clubs fragrances averages\n",
      "    subjectivists apprehensions muses factory-jobs ...\n",
      "PDT: pre-determiner\n",
      "    all both half many quite such sure this\n",
      "POS: genitive marker\n",
      "    ' 's\n",
      "PRP: pronoun, personal\n",
      "    hers herself him himself hisself it itself me myself one oneself ours\n",
      "    ourselves ownself self she thee theirs them themselves they thou thy us\n",
      "PRP$: pronoun, possessive\n",
      "    her his mine my our ours their thy your\n",
      "RB: adverb\n",
      "    occasionally unabatingly maddeningly adventurously professedly\n",
      "    stirringly prominently technologically magisterially predominately\n",
      "    swiftly fiscally pitilessly ...\n",
      "RBR: adverb, comparative\n",
      "    further gloomier grander graver greater grimmer harder harsher\n",
      "    healthier heavier higher however larger later leaner lengthier less-\n",
      "    perfectly lesser lonelier longer louder lower more ...\n",
      "RBS: adverb, superlative\n",
      "    best biggest bluntest earliest farthest first furthest hardest\n",
      "    heartiest highest largest least less most nearest second tightest worst\n",
      "RP: particle\n",
      "    aboard about across along apart around aside at away back before behind\n",
      "    by crop down ever fast for forth from go high i.e. in into just later\n",
      "    low more off on open out over per pie raising start teeth that through\n",
      "    under unto up up-pp upon whole with you\n",
      "SYM: symbol\n",
      "    % & ' '' ''. ) ). * + ,. < = > @ A[fj] U.S U.S.S.R * ** ***\n",
      "TO: \"to\" as preposition or infinitive marker\n",
      "    to\n",
      "UH: interjection\n",
      "    Goodbye Goody Gosh Wow Jeepers Jee-sus Hubba Hey Kee-reist Oops amen\n",
      "    huh howdy uh dammit whammo shucks heck anyways whodunnit honey golly\n",
      "    man baby diddle hush sonuvabitch ...\n",
      "VB: verb, base form\n",
      "    ask assemble assess assign assume atone attention avoid bake balkanize\n",
      "    bank begin behold believe bend benefit bevel beware bless boil bomb\n",
      "    boost brace break bring broil brush build ...\n",
      "VBD: verb, past tense\n",
      "    dipped pleaded swiped regummed soaked tidied convened halted registered\n",
      "    cushioned exacted snubbed strode aimed adopted belied figgered\n",
      "    speculated wore appreciated contemplated ...\n",
      "VBG: verb, present participle or gerund\n",
      "    telegraphing stirring focusing angering judging stalling lactating\n",
      "    hankerin' alleging veering capping approaching traveling besieging\n",
      "    encrypting interrupting erasing wincing ...\n",
      "VBN: verb, past participle\n",
      "    multihulled dilapidated aerosolized chaired languished panelized used\n",
      "    experimented flourished imitated reunifed factored condensed sheared\n",
      "    unsettled primed dubbed desired ...\n",
      "VBP: verb, present tense, not 3rd person singular\n",
      "    predominate wrap resort sue twist spill cure lengthen brush terminate\n",
      "    appear tend stray glisten obtain comprise detest tease attract\n",
      "    emphasize mold postpone sever return wag ...\n",
      "VBZ: verb, present tense, 3rd person singular\n",
      "    bases reconstructs marks mixes displeases seals carps weaves snatches\n",
      "    slumps stretches authorizes smolders pictures emerges stockpiles\n",
      "    seduces fizzes uses bolsters slaps speaks pleads ...\n",
      "WDT: WH-determiner\n",
      "    that what whatever which whichever\n",
      "WP: WH-pronoun\n",
      "    that what whatever whatsoever which who whom whosoever\n",
      "WP$: WH-pronoun, possessive\n",
      "    whose\n",
      "WRB: Wh-adverb\n",
      "    how however whence whenever where whereby whereever wherein whereof why\n",
      "``: opening quotation mark\n",
      "    ` ``\n"
     ]
    }
   ],
   "source": [
    "nltk.help.upenn_tagset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['As', 'ações', 'do', 'Magazine', 'Luiza', 'S.A.', ',', 'Franca', ',', 'Brasil', ',', 'acumularam', 'baixa', 'de', '70', '%', 'ao', 'ano', '.'], ['Assim', 'já', 'devolveram', 'todos', 'os', 'ganhos', 'do', 'período', 'da', 'pandemeia']]\n"
     ]
    }
   ],
   "source": [
    "token2 = sent_tokenize(Texto)\n",
    "\n",
    "ntokens = []\n",
    "for tokensentenca in token2:\n",
    "  ntokens.append(word_tokenize(tokensentenca))\n",
    "\n",
    "print(ntokens)\n",
    "\n",
    "possenteca = pos_tag_sents(ntokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'ações', 'Magazine', 'Luiza', 'S.A.', 'Franca', 'Brasil', 'acumularam', 'baixa', '70', 'ano', 'Assim', 'devolveram', 'todos', 'ganhos', 'período', 'pandemeia']\n",
      "['As', 'ações', 'Magazine', 'Luiza', 'S.A.', ',', 'Franca', ',', 'Brasil', ',', 'acumularam', 'baixa', '70', '%', 'ano', '.', 'Assim', 'devolveram', 'todos', 'ganhos', 'período', 'pandemeia']\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "resultado = [lemmatizer.lemmatize(palavra) for palavra in palavras_sem_stopwords]\n",
    "print(palavras_sem_pontuacao)\n",
    "print(resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (PERSON Barack/NNP)\n",
      "  (ORGANIZATION Obama/NNP)\n",
      "  foi/NN\n",
      "  um/JJ\n",
      "  presidente/NN\n",
      "  dos/NN\n",
      "  (ORGANIZATION EUA/NNP))\n"
     ]
    }
   ],
   "source": [
    "texto_en = \"Barack Obama foi um presidente dos EUA\"\n",
    "token3 = word_tokenize(texto_en)\n",
    "tags = pos_tag(token3)\n",
    "en = nltk.ne_chunk(tags)\n",
    "print(en)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
